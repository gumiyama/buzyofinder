#!/usr/bin/env python
import os
import sys
import time
from pathlib import Path

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã‚’Pythonãƒ‘ã‚¹ã«è¿½åŠ 
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from src.models.database import get_session, get_engine
from src.scrapers.suumo_scraper import SuumoScraper
from scripts.collect_tokyo23 import process_area

# å¤§äº•ç”ºï¼ˆå“å·åŒºï¼‰ã‚’é›†ä¸­çš„ã«
# å¤§äº•ç”ºã¯å“å·åŒºã®ä¸­å¿ƒçš„ãªã‚¨ãƒªã‚¢ãªã®ã§ã€å“å·åŒºã‚’æ·±ãæ˜ã‚‹ã“ã¨ã§ç¶²ç¾…ã§ãã‚‹
AREAS = {
    'shinagawa': {'pages': 40, 'name': 'å“å·åŒºï¼ˆå¤§äº•ç”ºä¸­å¿ƒï¼‰'}, # 40ãƒšãƒ¼ã‚¸åˆ†ã‚¬ãƒƒãƒ„ãƒªå–ã‚‹
}

def main():
    print("=" * 60)
    print("ğŸš€ å¤§äº•ç”ºï¼ˆå“å·åŒºï¼‰é›†ä¸­åé›†ãƒ¢ãƒ¼ãƒ‰")
    print("=" * 60)
    
    engine = get_engine()
    session = get_session(engine)
    scraper = SuumoScraper(interval=1.0)
    
    total_saved = 0
    
    try:
        for area_code, config in AREAS.items():
            print(f"\n{config['name']} ã®å‡¦ç†ã‚’é–‹å§‹")
            count = process_area(area_code, config, session, scraper)
            total_saved += count
            print(f"  âœ¨ {config['name']} å®Œäº†: +{count}ä»¶")
            
    except KeyboardInterrupt:
        print("\nğŸ›‘ ä¸­æ–­ã•ã‚Œã¾ã—ãŸ")
    finally:
        session.close()
        print("\n" + "=" * 60)
        print(f"ğŸ çµ‚äº†ã€‚æ–°è¦ä¿å­˜: {total_saved}ä»¶")

if __name__ == '__main__':
    main()
